## Assignment 4-Text Classification
本次实验数据来自THUCNews中的10个类别，每个类别抽取了6500条数据（训练集5000条、验证集500条、测试集1000条），将所有类别的数据整合为三个文件，此外还额外提供了词汇表文件 cnews.vocab.txt，包含5000个词汇，采用字符级表示

如果选择深度学习方法：

自行训练带有负采样的 skip-gram，可使用 gensim 工具包

利用训练好的词嵌入搭配卷积神经网络作为分类模型，在训练集上训练，并在验证集上进行调试，实现可参考TextCNN

使用多分类精确率、召回率和F1值作为评估指标，注意需要报告测试集中每个类别的指标以及整体的微平均指标

如果选择机器学习方法：

使用Bi-gram作为特征单元，统计并计算所有类别中Bi-gram的TF-IDF值

使用卡方检验选取特征单元，Chi-square算法可使用sklearn工具的chi2函数

使用sklearn中的Logistics Regression或SVM作为分类模型，在训练集上训练，并在验证集上进行调试

使用多分类精确率、召回率和F1值作为评估指标，注意需要报告测试集中每个类别的指标以及整体的微平均指标

### 文件说明及要求
- 提供的代码文件包含了大部分的skip-gram和CNN训练脚本
- 需要按照要求补充`dataset.py`, `model/cnn.py`和 `util.py`的“TODO”部分
- 运行 `python -u main.py`, 训练skip-gram模型需要10分钟左右, 训练CNN模型需要10分钟左右
- 默认参数训练及测试结果如下
```
各类别Precision: [0.999, 0.9418, 0.9822, 0.8036, 0.9374, 0.9798, 0.9197, 0.9554, 0.9171, 0.9406]
各类别Recall: [0.99, 0.987, 0.719, 0.929, 0.899, 0.972, 0.928, 0.964, 0.973, 0.981]
各类别F1: [0.9945, 0.9639, 0.8303, 0.8618, 0.9178, 0.9759, 0.9238, 0.9597, 0.9442, 0.9604]
整体微平均Precision: 0.9342
整体微平均Recall: 0.9342
整体微平均F1: 0.9342
```
- 也可以自行实现机器学习方法